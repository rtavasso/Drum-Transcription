audio:
  f_max: 20000
  f_min: 20
  hop_length: 512
  hop_size_ms: 10
  midi_sample_rate: 100
  n_fft: 2048
  n_mels: 128
  noise_level_range:
  - 0.0
  - 0.01
  pitch_shift_range:
  - -2
  - 2
  sample_rate: 44100
  time_stretch_range:
  - 0.95
  - 1.05
  use_augmentation: true
  window_size_ms: 25
audio_config:
  hop_length: 512
  midi_sample_rate: 100
  n_fft: 2048
  n_mels: 128
  sample_rate: 44100
data_dir: ../data/synthetic
inference:
  batch_size: 1
  checkpoint_path: best_model.pt
  device: cuda
  evaluate: true
  min_gap_ms: 10
  onset_threshold: 0.5
  save_midi: true
  save_predictions: true
  save_visualizations: false
  tolerance_ms: 50.0
model:
  encoder:
    base_channels: 16
    dropout: 0.2
    input_channels: 1
    kernel_sizes:
    - 7
    - 5
    - 3
    - 3
    paddings:
    - 3
    - 2
    - 1
    - 1
    strides:
    - 2
    - 2
    - 1
    - 1
  learning_rate: 0.001
  model_name: cnn_lstm
  onset_loss_weight: 1.0
  onset_positive_weight: 5.0
  temporal:
    dropout: 0.2
    hidden_dim: 256
    num_layers: 2
  velocity_loss_weight: 0.5
  weight_decay: 1.0e-05
model_config:
  encoder:
    base_channels: 8
    dropout: 0.1
    input_channels: 1
    kernel_sizes:
    - 7
    - 5
    - 3
    paddings:
    - 3
    - 2
    - 1
    strides:
    - 2
    - 2
    - 1
  learning_rate: 0.001
  model_name: cnn_lstm
  onset_loss_weight: 1.0
  onset_positive_weight: 5.0
  temporal:
    dropout: 0.1
    hidden_dim: 64
    num_layers: 1
  velocity_loss_weight: 0.5
  weight_decay: 1e-5
training:
  batch_size: 32
  checkpoint_dir: ./checkpoints
  dataset_path: ./data
  device: cuda
  early_stopping_patience: 10
  grad_clip_value: 1.0
  learning_rate: 0.001
  log_dir: ./logs
  mixed_precision: true
  num_epochs: 100
  num_workers: 4
  sample_length: 5.0
  seed: 42
  test_split: 0.1
  use_wandb: false
  val_split: 0.1
  wandb_project: drum-transcription
  weight_decay: 1.0e-05
training_config:
  batch_size: 4
  checkpoint_dir: ..\models\test_run\checkpoints
  device: !!python/object/apply:torch.device
  - cuda
  - 0
  early_stopping_patience: 5
  grad_clip_value: 1.0
  learning_rate: 0.001
  mixed_precision: true
  num_epochs: 3
  num_workers: 1
  use_wandb: false
  weight_decay: 1e-5
